{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b57facc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "df = pd.read_pickle('df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e291d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recupera_list_ss(task, stage, fold, model, emb, ft):\n",
    "    if ft == '-FT':\n",
    "        with open(f\"finetuning_ss/{task}_{stage}_{fold}_{emb}\", 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                if model in line:\n",
    "                    split_string = model + ': '\n",
    "                    split_line = line.split(split_string)\n",
    "                    pred_list = ast.literal_eval(split_line[1])\n",
    "                    return pred_list\n",
    "    else:\n",
    "        with open(f\"pre-trained_ss/{task}_{stage}_{fold}_{emb}\", 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                if model in line:\n",
    "                    split_string = model + ': '\n",
    "                    split_line = line.split(split_string)\n",
    "                    pred_list = ast.literal_eval(split_line[1])\n",
    "                    return pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e196898d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hits_at(k, true, preds):\n",
    "    return np.mean([1 if t in preds[:k] else 0 for t in true])\n",
    "\n",
    "def evaluate(task, fold, estagio, model, emb, ft='-FT'):\n",
    "    file_path = f'splits/test_doi_{task}_{fold}_{estagio}.csv'\n",
    "    doi_list = pd.read_csv(file_path)['node'].tolist()\n",
    "    filtered_df = df[df['doi'].isin(doi_list)]\n",
    "    k_dict = {\"name\": 50, \"bioActivity\": 5, \"collectionSpecie\": 50, \"collectionType\": 1, \"collectionSite\": 20}\n",
    "    scores = []\n",
    "    preds = recupera_list_ss(task, estagio, fold, model, emb, ft)\n",
    "    i=0\n",
    "    for _, row in filtered_df.iterrows():\n",
    "        scores.append(hits_at(k_dict[task], row[task], preds[i]))\n",
    "        i+=1 \n",
    "    result = f\"Tarefa: {task} | Estagio: {estagio} | Fold: {fold} | Hits@{k_dict[task]}: {np.mean(scores)}\\n\"\n",
    "    with open('./results_ss/resultados'+ft+'-SS-'+emb+'-'+str(model)+'.txt', 'a', encoding='utf-8') as f:\n",
    "        f.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c91efac",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "tarefas = ['collectionType', 'collectionSite', 'bioActivity', 'collectionSpecie', 'name']\n",
    "models = ['qwen14b', 'phi14b','llama8b']\n",
    "embedding_models = ['all-MiniLM-L6-v2', 'Qwen3-Embedding-0.6B', 'bge-m3', 'paraphrase-multilingual-MiniLM-L12-v2', 'multilingual-e5-large']\n",
    "\n",
    "for model in models:\n",
    "    for tarefa in tarefas:\n",
    "        for fold in folds:\n",
    "            for estagio in ['1st', '2nd', '3rd', '4th']:\n",
    "                for emb in embedding_models:\n",
    "                    evaluate(tarefa, fold, estagio, model, emb, ft='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "70ccfd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: qwen14b\n",
      "Embedding: all-MiniLM-L6-v2\n",
      "& .61 & .64 & .64 & .67 \n",
      "& .70 & .72 & .74 & .74 \n",
      "& .86 & .88 & .90 & .91 \n",
      "& .62 & .62 & .64 & .66 \n",
      "& .92 & .92 & .93 & .94 \n",
      "Model: qwen14b\n",
      "Embedding: Qwen3-Embedding-0.6B\n",
      "& .59 & .62 & .62 & .63 \n",
      "& .71 & .73 & .75 & .76 \n",
      "& .89 & .90 & .91 & .92 \n",
      "& .58 & .58 & .60 & .62 \n",
      "& .92 & .92 & .93 & .94 \n",
      "Model: qwen14b\n",
      "Embedding: bge-m3\n",
      "& .62 & .64 & .65 & .67 \n",
      "& .71 & .73 & .75 & .76 \n",
      "& .89 & .91 & .92 & .92 \n",
      "& .62 & .63 & .64 & .66 \n",
      "& .92 & .92 & .93 & .94 \n",
      "Model: qwen14b\n",
      "Embedding: paraphrase-multilingual-MiniLM-L12-v2\n",
      "& .57 & .60 & .61 & .63 \n",
      "& .70 & .72 & .73 & .74 \n",
      "& .78 & .79 & .80 & .79 \n",
      "& .61 & .61 & .63 & .65 \n",
      "& .92 & .92 & .93 & .94 \n",
      "Model: qwen14b\n",
      "Embedding: multilingual-e5-large\n",
      "& .61 & .64 & .64 & .66 \n",
      "& .71 & .73 & .74 & .75 \n",
      "& .89 & .91 & .91 & .92 \n",
      "& .62 & .62 & .64 & .66 \n",
      "& .92 & .92 & .93 & .94 \n",
      "Model: phi14b\n",
      "Embedding: all-MiniLM-L6-v2\n",
      "& .65 & .68 & .69 & .70 \n",
      "& .73 & .74 & .75 & .74 \n",
      "& .83 & .84 & .86 & .87 \n",
      "& .61 & .61 & .63 & .64 \n",
      "& .91 & .92 & .93 & .94 \n",
      "Model: phi14b\n",
      "Embedding: Qwen3-Embedding-0.6B\n",
      "& .64 & .66 & .67 & .68 \n",
      "& .74 & .75 & .76 & .75 \n",
      "& .89 & .89 & .90 & .89 \n",
      "& .59 & .58 & .60 & .61 \n",
      "& .91 & .92 & .93 & .94 \n",
      "Model: phi14b\n",
      "Embedding: bge-m3\n",
      "& .65 & .68 & .69 & .69 \n",
      "& .74 & .75 & .76 & .75 \n",
      "& .86 & .87 & .88 & .87 \n",
      "& .62 & .62 & .64 & .64 \n",
      "& .91 & .92 & .93 & .94 \n",
      "Model: phi14b\n",
      "Embedding: paraphrase-multilingual-MiniLM-L12-v2\n",
      "& .62 & .65 & .66 & .67 \n",
      "& .73 & .74 & .75 & .75 \n",
      "& .76 & .77 & .78 & .79 \n",
      "& .61 & .61 & .63 & .64 \n",
      "& .91 & .92 & .93 & .94 \n",
      "Model: phi14b\n",
      "Embedding: multilingual-e5-large\n",
      "& .64 & .66 & .67 & .68 \n",
      "& .74 & .75 & .76 & .75 \n",
      "& .86 & .87 & .88 & .87 \n",
      "& .61 & .61 & .64 & .64 \n",
      "& .91 & .92 & .93 & .94 \n",
      "Model: llama8b\n",
      "Embedding: all-MiniLM-L6-v2\n",
      "& .69 & .72 & .73 & .76 \n",
      "& .73 & .74 & .76 & .76 \n",
      "& .83 & .85 & .86 & .87 \n",
      "& .61 & .62 & .63 & .64 \n",
      "& .91 & .92 & .93 & .94 \n",
      "Model: llama8b\n",
      "Embedding: Qwen3-Embedding-0.6B\n",
      "& .67 & .69 & .70 & .71 \n",
      "& .74 & .74 & .76 & .77 \n",
      "& .89 & .89 & .89 & .87 \n",
      "& .59 & .60 & .61 & .61 \n",
      "& .91 & .92 & .93 & .94 \n",
      "Model: llama8b\n",
      "Embedding: bge-m3\n",
      "& .70 & .72 & .73 & .74 \n",
      "& .74 & .74 & .76 & .77 \n",
      "& .86 & .87 & .88 & .85 \n",
      "& .61 & .62 & .63 & .63 \n",
      "& .91 & .92 & .93 & .94 \n",
      "Model: llama8b\n",
      "Embedding: paraphrase-multilingual-MiniLM-L12-v2\n",
      "& .66 & .69 & .70 & .72 \n",
      "& .73 & .74 & .75 & .76 \n",
      "& .78 & .79 & .80 & .77 \n",
      "& .61 & .61 & .62 & .63 \n",
      "& .91 & .92 & .93 & .94 \n",
      "Model: llama8b\n",
      "Embedding: multilingual-e5-large\n",
      "& .70 & .72 & .73 & .74 \n",
      "& .74 & .74 & .76 & .77 \n",
      "& .86 & .88 & .88 & .86 \n",
      "& .63 & .63 & .64 & .65 \n",
      "& .91 & .92 & .93 & .94 \n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "def parse_line(line):\n",
    "    pattern = r\"Tarefa: (.*?) \\| Estagio: (.*?) \\| Fold: (\\d+) \\| (Hits@\\d+): ([0-9.]+)\"\n",
    "    match = re.match(pattern, line.strip())\n",
    "    if match:\n",
    "        tarefa, estagio, fold, metrica, valor = match.groups()\n",
    "        return tarefa, estagio, int(fold), metrica, float(valor)\n",
    "    return None\n",
    "\n",
    "def process_file(file_path):\n",
    "    resultados = defaultdict(list)\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parsed = parse_line(line)\n",
    "            if parsed:\n",
    "                tarefa, estagio, _, metrica, valor = parsed\n",
    "                resultados[(tarefa, estagio, metrica)].append(valor)\n",
    "\n",
    "    # Gera resumo\n",
    "    resumo = []\n",
    "    r2 = {}\n",
    "    for (tarefa, estagio, metrica), valores in sorted(resultados.items()):\n",
    "        media = sum(valores) / len(valores)\n",
    "        resumo.append((tarefa, estagio, metrica, len(valores), media))\n",
    "        r2[(tarefa, estagio)] = round(media,2)\n",
    "\n",
    "    return resumo, r2\n",
    "\n",
    "def imprimir_resumo(resumo):\n",
    "    print(f\"{'Tarefa':<20} {'Estagio':<10} {'Metrica':<10} {'Folds':<6} {'Media':<10}\")\n",
    "    print(\"-\" * 65)\n",
    "    for tarefa, estagio, metrica, num_folds, media in resumo:\n",
    "        print(f\"{tarefa:<20} {estagio:<10} {metrica:<10} {num_folds:<6} {media:<10.4f}\")\n",
    "    print(\"-\" * 65)\n",
    "\n",
    "\n",
    "ft = '-FT'\n",
    "for model in models:\n",
    "    for emb in embedding_models:\n",
    "        print('Model: ' + model)\n",
    "        print('Embedding: ' + emb)\n",
    "        caminho_arquivo = './results_ss/resultados'+ft+'-SS-'+emb+'-'+str(model)+'.txt'\n",
    "        resumo, r2 = process_file(caminho_arquivo)\n",
    "        tarefas = ['name', 'bioActivity', 'collectionSpecie', 'collectionSite', 'collectionType']\n",
    "        estagios = ['1st', '2nd', '3rd', '4th']\n",
    "        for tarefa in tarefas:\n",
    "            for estagio in estagios:\n",
    "                valor = r2[(tarefa, estagio)]  \n",
    "                print(\"&\", end=' ') \n",
    "                print(f'{valor:.2f}'.lstrip('0'), end =' ')\n",
    "            print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bike",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
