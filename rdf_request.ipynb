{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rdflib\n",
    "from dotenv import load_dotenv\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = []\n",
    "\n",
    "g = rdflib.Graph()\n",
    "\n",
    "def fetch_sparql_results():\n",
    "    sparql_result = []\n",
    "    offset = 0\n",
    "    sparql_batch_size = 100  # Batch size for SPARQL queries\n",
    "    more_results = True\n",
    "\n",
    "    while more_results:\n",
    "        try:\n",
    "            sparql_query = f\"\"\"\n",
    "                            PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "                            PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "                            select ?label where {{\n",
    "                                SERVICE <https://nubbekg.aksw.org/sparql> {{\n",
    "                                    ?s a <http://nubbekg.aksw.org/ontology#IsolationSite> .\n",
    "                                    ?s rdfs:label ?label .\n",
    "                                }}\n",
    "                            }} LIMIT {sparql_batch_size} OFFSET {offset}\n",
    "                            \"\"\"\n",
    "            current_results = g.query(sparql_query)\n",
    "            current_results = list(current_results)\n",
    "            if not current_results or len(current_results) < sparql_batch_size:\n",
    "                more_results = False\n",
    "            else:\n",
    "                offset += sparql_batch_size\n",
    "                sparql_result.extend(current_results)\n",
    "        except Exception as e:\n",
    "            print(\"Exception when querying SPARQL endpoint\" + \": %s\" % e)\n",
    "            break\n",
    "\n",
    "    return sparql_result\n",
    "\n",
    "sparq_result = fetch_sparql_results()\n",
    "\n",
    "for entry in sparq_result:\n",
    "    label = entry.label\n",
    "    doc = Document(page_content=label, metadata={'label': label})\n",
    "    entities.append(doc)\n",
    "\n",
    "# Create FAISS index from documents\n",
    "faiss_index = FAISS.from_documents(entities, embeddings)\n",
    "\n",
    "# Save the FAISS index locally\n",
    "faiss_index.save_local(\"faiss_index\")\n",
    "\n",
    "# Load the FAISS index, allowing deserialization\n",
    "loaded_faiss_index = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "# Perform a similarity search\n",
    "query = \"Minas Gerais\"\n",
    "docs_with_score = loaded_faiss_index.similarity_search_with_score(query, top_k=5)\n",
    "\n",
    "for doc, score in docs_with_score:\n",
    "    print(f\"Document: {doc.page_content}, Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching results for Compound...\n",
      "No results found for Compound\n",
      "\n",
      "Fetching results for Bioactivity...\n",
      "No results found for Bioactivity\n",
      "\n",
      "Fetching results for Species...\n",
      "Results for Species:\n",
      "Document: Brosimum paraense, Score: 0.3206876218318939\n",
      "Document: Hortia brasiliana, Score: 0.36012303829193115\n",
      "Document: Tovomita brasiliensis, Score: 0.36122336983680725\n",
      "Document: Strychnos brasiliensis, Score: 0.3688787519931793\n",
      "\n",
      "\n",
      "Fetching results for IsolationSite...\n",
      "Results for IsolationSite:\n",
      "Document: Minas Novas ,MG, Score: 0.12228038907051086\n",
      "Document: Brasilandia De Minas ,MG, Score: 0.13958212733268738\n",
      "Document: Brasilia De Minas ,MG, Score: 0.14308050274848938\n",
      "Document: Maripa De Minas ,MG, Score: 0.15157777070999146\n",
      "\n",
      "\n",
      "Fetching results for IsolationType...\n",
      "No results found for IsolationType\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import rdflib\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "attributes = {\n",
    "    \"Compound\": \"http://nubbekg.aksw.org/ontology#Compound\",\n",
    "    \"Bioactivity\": \"http://nubbekg.aksw.org/ontology#Bioactivity\",\n",
    "    \"Species\": \"http://nubbekg.aksw.org/ontology#Species\",\n",
    "    \"IsolationSite\": \"http://nubbekg.aksw.org/ontology#IsolationSite\",\n",
    "    \"IsolationType\": \"http://nubbekg.aksw.org/ontology#IsolationType\"\n",
    "}\n",
    "\n",
    "g = rdflib.Graph()\n",
    "\n",
    "def fetch_sparql_results(attribute_uri):\n",
    "    sparql_result = []\n",
    "    offset = 0\n",
    "    sparql_batch_size = 100  # Batch size for SPARQL queries\n",
    "    more_results = True\n",
    "\n",
    "    while more_results:\n",
    "        try:\n",
    "            sparql_query = f\"\"\"\n",
    "                            PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "                            PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "                            select ?label where {{\n",
    "                                SERVICE <https://nubbekg.aksw.org/sparql> {{\n",
    "                                    ?s a <{attribute_uri}> .\n",
    "                                    ?s rdfs:label ?label .\n",
    "                                }}\n",
    "                            }} LIMIT {sparql_batch_size} OFFSET {offset}\n",
    "                            \"\"\"\n",
    "            current_results = g.query(sparql_query)\n",
    "            current_results = list(current_results)\n",
    "            if not current_results or len(current_results) < sparql_batch_size:\n",
    "                more_results = False\n",
    "            else:\n",
    "                offset += sparql_batch_size\n",
    "                sparql_result.extend(current_results)\n",
    "        except Exception as e:\n",
    "            print(f\"Exception when querying SPARQL endpoint for {attribute_uri}: {e}\")\n",
    "            break\n",
    "\n",
    "    return sparql_result\n",
    "\n",
    "# Ensure the faiss_index directory exists\n",
    "os.makedirs(\"faiss_index\", exist_ok=True)\n",
    "\n",
    "for attribute_name, attribute_uri in attributes.items():\n",
    "    entities = []\n",
    "    print(f\"Fetching results for {attribute_name}...\")\n",
    "    sparql_results = fetch_sparql_results(attribute_uri)\n",
    "\n",
    "    for entry in sparql_results:\n",
    "        label = entry.label\n",
    "        doc = Document(page_content=label, metadata={'label': label})\n",
    "        entities.append(doc)\n",
    "\n",
    "    if entities:\n",
    "        # Create FAISS index from documents\n",
    "        faiss_index = FAISS.from_documents(entities, embeddings)\n",
    "\n",
    "        # Save the FAISS index locally with attribute-specific naming\n",
    "        index_path = os.path.join(\"faiss_index\", f\"faiss_index_{attribute_name}\")\n",
    "        faiss_index.save_local(index_path)\n",
    "\n",
    "        # Load the FAISS index, allowing deserialization\n",
    "        loaded_faiss_index = FAISS.load_local(index_path, embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "        # Perform a similarity search\n",
    "        query = \"Minas Gerais\"\n",
    "        docs_with_score = loaded_faiss_index.similarity_search_with_score(query, top_k=5)\n",
    "\n",
    "        print(f\"Results for {attribute_name}:\")\n",
    "        for doc, score in docs_with_score:\n",
    "            print(f\"Document: {doc.page_content}, Score: {score}\")\n",
    "        print(\"\\n\")\n",
    "    else:\n",
    "        print(f\"No results found for {attribute_name}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
